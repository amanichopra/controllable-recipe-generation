{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T5 Model Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Train/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "\n",
    "def get_df_from_gcs_blob(blob, bucket='recipe-data-bucket'):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket)\n",
    "\n",
    "    blob = bucket.blob(blob)\n",
    "    blob = blob.download_as_string()\n",
    "    blob = blob.decode()\n",
    "    blob = StringIO(blob)  #tranform bytes to string here\n",
    "    df = pd.read_csv(blob)\n",
    "    return df\n",
    "\n",
    "train_df = get_df_from_gcs_blob('train.csv')\n",
    "test_df = get_df_from_gcs_blob('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;start-ingredients&gt;salmon steaks, olive oil, S...</td>\n",
       "      <td>&lt;start-title&gt;Broiled Salmon Steaks&lt;end-title&gt;&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;start-ingredients&gt;rice, scallops, rice wine, ...</td>\n",
       "      <td>&lt;start-title&gt;Sticky Rice With Chinese Sausage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;start-ingredients&gt;escarole, Medjool dates, wa...</td>\n",
       "      <td>&lt;start-title&gt;Escarole With Bacon, Dates, And W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;start-ingredients&gt;skirt steak, garlic, olive ...</td>\n",
       "      <td>&lt;start-title&gt;Grilled Garlic-Marinated Skirt St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;start-ingredients&gt;ricotta, honey, vanilla ext...</td>\n",
       "      <td>&lt;start-title&gt;Honeyed Ricotta&lt;end-title&gt;&lt;start-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  <start-ingredients>salmon steaks, olive oil, S...   \n",
       "1  <start-ingredients>rice, scallops, rice wine, ...   \n",
       "2  <start-ingredients>escarole, Medjool dates, wa...   \n",
       "3  <start-ingredients>skirt steak, garlic, olive ...   \n",
       "4  <start-ingredients>ricotta, honey, vanilla ext...   \n",
       "\n",
       "                                              output  \n",
       "0  <start-title>Broiled Salmon Steaks<end-title><...  \n",
       "1  <start-title>Sticky Rice With Chinese Sausage ...  \n",
       "2  <start-title>Escarole With Bacon, Dates, And W...  \n",
       "3  <start-title>Grilled Garlic-Marinated Skirt St...  \n",
       "4  <start-title>Honeyed Ricotta<end-title><start-...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;start-ingredients&gt;fennel bulb ani, onion, ted...</td>\n",
       "      <td>&lt;start-title&gt;Potato And Fennel Soup Hodge&lt;end-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;start-ingredients&gt;spinach soufflé, extra egg ...</td>\n",
       "      <td>&lt;start-title&gt;Spinach Noodle Casserole&lt;end-titl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;start-ingredients&gt;soy sauce, sugar, Asian ses...</td>\n",
       "      <td>&lt;start-title&gt;Korean Marinated Beef&lt;end-title&gt;&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;start-ingredients&gt;pecan halves, ted butter, s...</td>\n",
       "      <td>&lt;start-title&gt;Sea Salt-Roasted Pecans&lt;end-title...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;start-ingredients&gt;garlic, olive oil, salt, bl...</td>\n",
       "      <td>&lt;start-title&gt;Garlic Baguette Crumbs&lt;end-title&gt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  <start-ingredients>fennel bulb ani, onion, ted...   \n",
       "1  <start-ingredients>spinach soufflé, extra egg ...   \n",
       "2  <start-ingredients>soy sauce, sugar, Asian ses...   \n",
       "3  <start-ingredients>pecan halves, ted butter, s...   \n",
       "4  <start-ingredients>garlic, olive oil, salt, bl...   \n",
       "\n",
       "                                              output  \n",
       "0  <start-title>Potato And Fennel Soup Hodge<end-...  \n",
       "1  <start-title>Spinach Noodle Casserole<end-titl...  \n",
       "2  <start-title>Korean Marinated Beef<end-title><...  \n",
       "3  <start-title>Sea Salt-Roasted Pecans<end-title...  \n",
       "4  <start-title>Garlic Baguette Crumbs<end-title>...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class T5Dataset:\n",
    "  def __init__(self, inps, outs, tokenizer, inp_max_len, out_max_len):   \n",
    "    self.inps = inps\n",
    "    self.outs = outs\n",
    "    self.tokenizer = tokenizer\n",
    "    self.input_max_len = inp_max_len\n",
    "    self.output_max_len = out_max_len\n",
    "  \n",
    "  def __len__(self):                      # This method retrives the number of item from the dataset\n",
    "    return len(self.inps)\n",
    "\n",
    "  def __getitem__(self, item):             # This method retrieves the item at the specified index item. \n",
    "    inp = str(self.inps[item])\n",
    "    out = str(self.outs[item])\n",
    "\n",
    "    input_tokenize = self.tokenizer(      \n",
    "            inp,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.input_max_len,\n",
    "            padding = 'max_length',\n",
    "            truncation = True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "    output_tokenize = self.tokenizer(\n",
    "            out,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.output_max_len,\n",
    "            padding = 'max_length',\n",
    "            truncation = True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\"\n",
    "            \n",
    "        )\n",
    "    \n",
    "\n",
    "    input_ids = input_tokenize[\"input_ids\"].flatten().to(dtype=torch.long)\n",
    "    attention_mask = input_tokenize[\"attention_mask\"].flatten().to(dtype=torch.long)\n",
    "    output_ids = output_tokenize['input_ids'].flatten().to(dtype=torch.long)\n",
    "\n",
    "    out = {\n",
    "            'input': inp,      \n",
    "            'target': out,\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'target_ids': output_ids\n",
    "        }\n",
    "        \n",
    "    return out \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "def train(tokenizer, model, device, loader, optimizer, fp16=False):\n",
    "    losses = []\n",
    "    if fp16: model.half()\n",
    "    model.train()\n",
    "    for _, data in enumerate(loader, 0):\n",
    "        y = data['target_ids'].to(device, dtype = torch.long)\n",
    "        y_ids = y[:, :-1].contiguous()\n",
    "        lm_labels = y[:, 1:].clone().detach()\n",
    "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "        ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)\n",
    "        loss = outputs[0]\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if _%10 == 0:\n",
    "            wandb.log({\"Training Loss\": loss.item()})\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "TEST_BATCH_SIZE = 16\n",
    "TRAIN_NUM_WORKERS = 2\n",
    "TEST_NUM_WORKERS = 2\n",
    "\n",
    "INP_MAX_LEN = max(train_df['input'].map(len).max(), test_df['input'].map(len).max())\n",
    "OUT_MAX_LEN = max(train_df['output'].map(len).max(), test_df['output'].map(len).max())\n",
    "INP_MAX_LEN = 100\n",
    "OUT_MAX_LEN = 100\n",
    "\n",
    "MOD = 't5-small'\n",
    "EPOCHS = 10\n",
    "LR = 1e-4\n",
    "DEVICE = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mamanichopra\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/amanchopra/controllable-recipe-generation/wandb/run-20231105_014752-d0xt7bwe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/amanichopra/recipe-t5/runs/d0xt7bwe' target=\"_blank\">zany-microwave-21</a></strong> to <a href='https://wandb.ai/amanichopra/recipe-t5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/amanichopra/recipe-t5' target=\"_blank\">https://wandb.ai/amanichopra/recipe-t5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/amanichopra/recipe-t5/runs/d0xt7bwe' target=\"_blank\">https://wandb.ai/amanichopra/recipe-t5/runs/d0xt7bwe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training in epoch 0...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/amanchopra/controllable-recipe-generation/train_t5.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcp-controllable-recipe-generation-deeplearning-1-vm/home/amanchopra/controllable-recipe-generation/train_t5.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(EPOCHS):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcp-controllable-recipe-generation-deeplearning-1-vm/home/amanchopra/controllable-recipe-generation/train_t5.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBeginning training in epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgcp-controllable-recipe-generation-deeplearning-1-vm/home/amanchopra/controllable-recipe-generation/train_t5.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m     losses \u001b[39m=\u001b[39m train(tokenizer, model, DEVICE, train_loader, opt)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcp-controllable-recipe-generation-deeplearning-1-vm/home/amanchopra/controllable-recipe-generation/train_t5.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m     epoch_running_loss \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(losses)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcp-controllable-recipe-generation-deeplearning-1-vm/home/amanchopra/controllable-recipe-generation/train_t5.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m     wandb\u001b[39m.\u001b[39mlog({\u001b[39m\"\u001b[39m\u001b[39mEpoch Running Training Loss\u001b[39m\u001b[39m\"\u001b[39m: epoch_running_loss})\n",
      "\u001b[1;32m/home/amanchopra/controllable-recipe-generation/train_t5.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcp-controllable-recipe-generation-deeplearning-1-vm/home/amanchopra/controllable-recipe-generation/train_t5.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(input_ids \u001b[39m=\u001b[39m ids, attention_mask \u001b[39m=\u001b[39m mask, decoder_input_ids\u001b[39m=\u001b[39my_ids, labels\u001b[39m=\u001b[39mlm_labels)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcp-controllable-recipe-generation-deeplearning-1-vm/home/amanchopra/controllable-recipe-generation/train_t5.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m loss \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgcp-controllable-recipe-generation-deeplearning-1-vm/home/amanchopra/controllable-recipe-generation/train_t5.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m losses\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39;49mitem())\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcp-controllable-recipe-generation-deeplearning-1-vm/home/amanchopra/controllable-recipe-generation/train_t5.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mif\u001b[39;00m _\u001b[39m%\u001b[39m\u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcp-controllable-recipe-generation-deeplearning-1-vm/home/amanchopra/controllable-recipe-generation/train_t5.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     wandb\u001b[39m.\u001b[39mlog({\u001b[39m\"\u001b[39m\u001b[39mTraining Loss\u001b[39m\u001b[39m\"\u001b[39m: loss\u001b[39m.\u001b[39mitem()})\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"recipe-t5\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"train_data_batch_size\": TRAIN_BATCH_SIZE,\n",
    "    \"train_dataloader_num_workers\": TRAIN_NUM_WORKERS,\n",
    "    \"test_data_batch_size\": TEST_BATCH_SIZE,\n",
    "    \"test_dataloader_num_workers\": TEST_NUM_WORKERS,\n",
    "    \"inp_max_len\": INP_MAX_LEN,\n",
    "    \"out_max_len\": OUT_MAX_LEN,\n",
    "    \"device\": DEVICE,\n",
    "    \"lr\": LR,\n",
    "    \"model\": MOD\n",
    "    }\n",
    ")\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(MOD)\n",
    "\n",
    "train_dataset = T5Dataset(train_df['input'].values, train_df['output'].values, tokenizer, INP_MAX_LEN, OUT_MAX_LEN)\n",
    "test_dataset = T5Dataset(test_df['input'].values, test_df['output'].values, tokenizer, INP_MAX_LEN, OUT_MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, num_workers=TRAIN_NUM_WORKERS, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, num_workers=TEST_NUM_WORKERS)\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(MOD).to(DEVICE)\n",
    "\n",
    "opt = torch.optim.Adam(params =  model.parameters(), lr=LR)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Beginning training in epoch {epoch}...\")\n",
    "    losses = train(tokenizer, model, DEVICE, train_loader, opt)\n",
    "    epoch_running_loss = sum(losses)\n",
    "    wandb.log({\"Epoch Running Training Loss\": epoch_running_loss})\n",
    "    print(f\"Epoch {epoch} Running Loss: {epoch_running_loss}\")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 7            |        cudaMalloc retries: 10        |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  15308 MiB |  15330 MiB |  57792 MiB |  42483 MiB |\n",
      "|       from large pool |  15306 MiB |  15326 MiB |  57772 MiB |  42465 MiB |\n",
      "|       from small pool |      1 MiB |      4 MiB |     20 MiB |     18 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  15308 MiB |  15330 MiB |  57792 MiB |  42483 MiB |\n",
      "|       from large pool |  15306 MiB |  15326 MiB |  57772 MiB |  42465 MiB |\n",
      "|       from small pool |      1 MiB |      4 MiB |     20 MiB |     18 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |  15285 MiB |  15316 MiB |  57718 MiB |  42432 MiB |\n",
      "|       from large pool |  15284 MiB |  15313 MiB |  57698 MiB |  42414 MiB |\n",
      "|       from small pool |      1 MiB |      4 MiB |     20 MiB |     18 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  15522 MiB |  15526 MiB |  37070 MiB |  21548 MiB |\n",
      "|       from large pool |  15520 MiB |  15520 MiB |  37062 MiB |  21542 MiB |\n",
      "|       from small pool |      2 MiB |      6 MiB |      8 MiB |      6 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory | 218442 KiB |   1967 MiB |  20139 MiB |  19926 MiB |\n",
      "|       from large pool | 218178 KiB |   1964 MiB |  20114 MiB |  19901 MiB |\n",
      "|       from small pool |    264 KiB |      4 MiB |     25 MiB |     25 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     966    |     967    |    2495    |    1529    |\n",
      "|       from large pool |     784    |     785    |    1915    |    1131    |\n",
      "|       from small pool |     182    |     184    |     580    |     398    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     966    |     967    |    2495    |    1529    |\n",
      "|       from large pool |     784    |     785    |    1915    |    1131    |\n",
      "|       from small pool |     182    |     184    |     580    |     398    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     152    |     153    |     231    |      79    |\n",
      "|       from large pool |     151    |     151    |     227    |      76    |\n",
      "|       from small pool |       1    |       3    |       4    |       3    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |     111    |     111    |     596    |     485    |\n",
      "|       from large pool |     107    |     107    |     525    |     418    |\n",
      "|       from small pool |       4    |       9    |      71    |      67    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'T5ForConditionalGeneration' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/amanchopra/controllable-recipe-generation/train_t5.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgcp-controllable-recipe-generation-deeplearning-1-vm/home/amanchopra/controllable-recipe-generation/train_t5.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49msize()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'T5ForConditionalGeneration' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "model.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
